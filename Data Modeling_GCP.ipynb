{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection & Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be using decision tree to identify the feature importance and use them as weights for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_pickle('eda_training.pickle')\n",
    "test = pd.read_pickle('eda_test.pickle')\n",
    "data_dict = pd.read_pickle('data_dict.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>New Column Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>Person experienced 90 days past due delinquenc...</td>\n",
       "      <td>Y/N</td>\n",
       "      <td>dlq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RevolvingUtilizationOfUnsecuredLines</td>\n",
       "      <td>Total balance on credit cards and personal lin...</td>\n",
       "      <td>percentage</td>\n",
       "      <td>util_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>Age of borrower in years</td>\n",
       "      <td>integer</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NumberOfTime30-59DaysPastDueNotWorse</td>\n",
       "      <td>Number of times borrower has been 30-59 days p...</td>\n",
       "      <td>integer</td>\n",
       "      <td>ph_30to59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DebtRatio</td>\n",
       "      <td>Monthly debt payments, alimony,living costs di...</td>\n",
       "      <td>percentage</td>\n",
       "      <td>debtratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MonthlyIncome</td>\n",
       "      <td>Monthly income</td>\n",
       "      <td>real</td>\n",
       "      <td>monthlyincome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NumberOfOpenCreditLinesAndLoans</td>\n",
       "      <td>Number of Open loans (installment like car loa...</td>\n",
       "      <td>integer</td>\n",
       "      <td>open_credit_loans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfTimes90DaysLate</td>\n",
       "      <td>Number of times borrower has been 90 days or m...</td>\n",
       "      <td>integer</td>\n",
       "      <td>ph_90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NumberRealEstateLoansOrLines</td>\n",
       "      <td>Number of mortgage and real estate loans inclu...</td>\n",
       "      <td>integer</td>\n",
       "      <td>realestate_lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NumberOfTime60-89DaysPastDueNotWorse</td>\n",
       "      <td>Number of times borrower has been 60-89 days p...</td>\n",
       "      <td>integer</td>\n",
       "      <td>ph_60to89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NumberOfDependents</td>\n",
       "      <td>Number of dependents in family excluding thems...</td>\n",
       "      <td>integer</td>\n",
       "      <td>dependents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Variable Name  \\\n",
       "0                       SeriousDlqin2yrs   \n",
       "1   RevolvingUtilizationOfUnsecuredLines   \n",
       "2                                    age   \n",
       "3   NumberOfTime30-59DaysPastDueNotWorse   \n",
       "4                              DebtRatio   \n",
       "5                          MonthlyIncome   \n",
       "6        NumberOfOpenCreditLinesAndLoans   \n",
       "7                NumberOfTimes90DaysLate   \n",
       "8           NumberRealEstateLoansOrLines   \n",
       "9   NumberOfTime60-89DaysPastDueNotWorse   \n",
       "10                    NumberOfDependents   \n",
       "\n",
       "                                          Description        Type  \\\n",
       "0   Person experienced 90 days past due delinquenc...         Y/N   \n",
       "1   Total balance on credit cards and personal lin...  percentage   \n",
       "2                            Age of borrower in years     integer   \n",
       "3   Number of times borrower has been 30-59 days p...     integer   \n",
       "4   Monthly debt payments, alimony,living costs di...  percentage   \n",
       "5                                      Monthly income        real   \n",
       "6   Number of Open loans (installment like car loa...     integer   \n",
       "7   Number of times borrower has been 90 days or m...     integer   \n",
       "8   Number of mortgage and real estate loans inclu...     integer   \n",
       "9   Number of times borrower has been 60-89 days p...     integer   \n",
       "10  Number of dependents in family excluding thems...     integer   \n",
       "\n",
       "     New Column Names  \n",
       "0                 dlq  \n",
       "1          util_ratio  \n",
       "2                 age  \n",
       "3           ph_30to59  \n",
       "4           debtratio  \n",
       "5       monthlyincome  \n",
       "6   open_credit_loans  \n",
       "7               ph_90  \n",
       "8    realestate_lines  \n",
       "9           ph_60to89  \n",
       "10         dependents  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training.drop('dlq',axis=1)\n",
    "y = training['dlq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_X = pd.read_pickle('SMOTE_res_x.pickle')\n",
    "res_y = pd.read_pickle('SMOTE_res_y.pickle')\n",
    "X_test = pd.read_pickle('scaled_X_test.pickle')\n",
    "y_test = pd.read_pickle('y_test.pickle')\n",
    "scaled_test = pd.read_pickle('scaled_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting AUC as scoring metrics\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "def roc_auc_score_proba(y_true, proba):\n",
    "    return roc_auc_score(y_true, proba[:, 1])\n",
    "\n",
    "auc = make_scorer(roc_auc_score_proba, needs_proba=True)# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using decision tree for feature selection using feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtc_params = {\n",
    "#     'max_depth':[1,2,3,4,5,6,7,8],\n",
    "#     'max_features':[None,'log2','sqrt',2,3,4],\n",
    "#     'min_samples_split':[2,3,4,5,10,15,20,25]\n",
    "# }\n",
    "\n",
    "\n",
    "# dtc_gs = GridSearchCV(DecisionTreeClassifier(random_state=2), dtc_params, cv=3, verbose=1,scoring=auc)\n",
    "# dtc_gs.fit(res_X, res_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance = dtc_gs.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance.dump('feature_importance.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.read_pickle('feature_importance.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>util_ratio</th>\n",
       "      <td>0.560359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph_30to59</th>\n",
       "      <td>0.197957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph_90</th>\n",
       "      <td>0.101242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph_60to89</th>\n",
       "      <td>0.038669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realestate_lines</th>\n",
       "      <td>0.033640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_credit_loans</th>\n",
       "      <td>0.030716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.017777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debtratio</th>\n",
       "      <td>0.012359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthlyincome</th>\n",
       "      <td>0.005810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependents</th>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "util_ratio         0.560359\n",
       "ph_30to59          0.197957\n",
       "ph_90              0.101242\n",
       "ph_60to89          0.038669\n",
       "realestate_lines   0.033640\n",
       "open_credit_loans  0.030716\n",
       "age                0.017777\n",
       "debtratio          0.012359\n",
       "monthlyincome      0.005810\n",
       "dependents         0.001472"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(feature_importance,index=X.columns).sort_values(by=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_X = np.multiply(res_X,feature_importance)\n",
    "weighted_X_test = np.multiply(X_test,feature_importance)\n",
    "weighted_test = np.multiply(scaled_test,feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logregcv = LogisticRegressionCV(n_jobs=-1, random_state=2, max_iter=200, cv=3,\\\n",
    "#                                 scoring=auc)\n",
    "# logregcv.fit(weighted_X, res_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('Training Score: {}'.format(logregcv.score(weighted_X,res_y)))   # training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('Test Score: {}'.format(logregcv.score(weighted_X_test,y_test)))   # test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import learning_curve\n",
    "\n",
    "# def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "#                         n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "#     \"\"\"\n",
    "#     Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "#         An object of that type which is cloned for each validation.\n",
    "\n",
    "#     title : string\n",
    "#         Title for the chart.\n",
    "\n",
    "#     X : array-like, shape (n_samples, n_features)\n",
    "#         Training vector, where n_samples is the number of samples and\n",
    "#         n_features is the number of features.\n",
    "\n",
    "#     y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "#         Target relative to X for classification or regression;\n",
    "#         None for unsupervised learning.\n",
    "\n",
    "#     ylim : tuple, shape (ymin, ymax), optional\n",
    "#         Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "#     cv : int, cross-validation generator or an iterable, optional\n",
    "#         Determines the cross-validation splitting strategy.\n",
    "#         Possible inputs for cv are:\n",
    "#           - None, to use the default 3-fold cross-validation,\n",
    "#           - integer, to specify the number of folds.\n",
    "#           - An object to be used as a cross-validation generator.\n",
    "#           - An iterable yielding train/test splits.\n",
    "\n",
    "#         For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "#         :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "#         or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "#         Refer :ref:`User Guide <cross_validation>` for the various\n",
    "#         cross-validators that can be used here.\n",
    "\n",
    "#     n_jobs : integer, optional\n",
    "#         Number of jobs to run in parallel (default 1).\n",
    "#     \"\"\"\n",
    "#     plt.figure()\n",
    "#     plt.title(title)\n",
    "#     if ylim is not None:\n",
    "#         plt.ylim(*ylim)\n",
    "#     plt.xlabel(\"Training examples\")\n",
    "#     plt.ylabel(\"Score\")\n",
    "#     train_sizes, train_scores, test_scores = learning_curve(\n",
    "#         estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,random_state=2)\n",
    "#     train_scores_mean = np.mean(train_scores, axis=1)\n",
    "#     train_scores_std = np.std(train_scores, axis=1)\n",
    "#     test_scores_mean = np.mean(test_scores, axis=1)\n",
    "#     test_scores_std = np.std(test_scores, axis=1)\n",
    "#     plt.grid()\n",
    "\n",
    "#     plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "#                      train_scores_mean + train_scores_std, alpha=0.1,\n",
    "#                      color=\"r\")\n",
    "#     plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "#                      test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "#     plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "#              label=\"Training score\")\n",
    "#     plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "#              label=\"Cross-validation score\")\n",
    "\n",
    "#     plt.legend(loc=\"best\")\n",
    "#     return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = 'Logistic Regression CV'\n",
    "# estimator = logregcv\n",
    "\n",
    "# from sklearn.utils import shuffle\n",
    "# X, y = shuffle(weighted_X, res_y)\n",
    "\n",
    "# plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "#                         n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our cross validation score is plateau-ing throughout. This shows that the validation set is unable to learn much from the training data. The training score decrease by only a little bit. It seems that our model is underfitting. We can try to increase the model complexity to see if we can improve on the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predict = logregcv.predict_proba(weighted_test)\n",
    "# test_predict = pd.DataFrame(test_predict)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame(np.arange(1, len(test_predict) + 1))\n",
    "# submission[1] = test_predict\n",
    "# submission = submission.rename({0:'Id',1:'Probability'},axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.set_index('Id').to_csv('submission_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"https://i.imgur.com/weWdohG.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first Kaggle submission using logistic regression cv provided a score of <b>0.857848 (Private)</b> and <b>0.852654 (Public)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 36.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 59.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 104.1min\n"
     ]
    }
   ],
   "source": [
    "# plot learning curve\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "parameters = {'learning_rate': [0.005,0.01],\n",
    "              'max_depth': [4,6,8],\n",
    "              'min_child_weight': [2,4,6,8],\n",
    "              'gamma': [1,2,4,6],\n",
    "              'subsample': [0.7,0.75,0.80],\n",
    "              'colsample_bytree': [0.15,0.3,0.45,0.6],\n",
    "              'n_estimators': [250]} #number of trees, change it to 1000 for better results}\n",
    "\n",
    "# fit model\n",
    "# model = XGBClassifier(max_depth=5, learning_rate=0.025, n_estimators=100, silent=True, \\\n",
    "#                       objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, \\\n",
    "#                       gamma=0.65, min_child_weight=10, max_delta_step=1.8, subsample=0.8, colsample_bytree=0.4, \\\n",
    "#                       colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, \\\n",
    "#                       random_state=2, seed=None, missing=None)\n",
    "\n",
    "estimator = XGBClassifier()\n",
    "model = GridSearchCV(estimator,parameters, n_jobs=-1,cv=5,verbose=True,scoring='roc_auc')\n",
    "\n",
    "eval_set = [(weighted_X,res_y), (np.array(weighted_X_test),np.array(y_test))]\n",
    "model.fit(weighted_X,res_y)\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, 'xgboost_model.pkl') \n",
    "\n",
    "# , eval_metric=[\"auc\"], eval_set=eval_set, verbose=True,early_stopping_rounds=50)\n",
    "\n",
    "# make predictions for test data\n",
    "# y_pred = model.predict(np.array(weighted_X_test))\n",
    "# predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# # evaluate predictions\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# auc = roc_auc_score(np.array(y_test), predictions)\n",
    "\n",
    "# print(\"AUC: %.2f%%\" % (auc * 100.0))\n",
    "\n",
    "# # retrieve performance metrics\n",
    "# results = model.evals_result()\n",
    "# epochs = len(results['validation_0']['auc'])\n",
    "# x_axis = range(0, epochs)\n",
    "\n",
    "# # plot auc\n",
    "# fig, ax = pyplot.subplots()\n",
    "# ax.plot(x_axis, results['validation_0']['auc'], label='Train')\n",
    "# ax.plot(x_axis, results['validation_1']['auc'], label='Test')\n",
    "# ax.legend()\n",
    "# pyplot.ylabel('AUC')\n",
    "# pyplot.title('XGBoost AUC')\n",
    "# pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
